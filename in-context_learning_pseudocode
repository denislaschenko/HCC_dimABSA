from openai import OpenAI
from transformers import BertTokenizer, BertForSequenceClassification
import torch

# ---------------------------
# STEP 1: Aspect/Dimension Extraction with an LLM
# ---------------------------

client = OpenAI()

review = "The food was delicious but the service was slow."

prompt = """
You are performing dimension-based aspect-based sentiment analysis (dimABSA).
Extract all (aspect, dimension) pairs from the review.

Examples:
1. "The room was clean and spacious." → [(room, cleanliness), (room, space)]
2. "Great taste but too expensive." → [(food, taste), (food, price)]

Now extract from this:
"{}"
""".format(review)

response = client.chat.completions.create(
    model="gpt-5",
    messages=[{"role": "user", "content": prompt}]
)

extracted_pairs = response.choices[0].message.content
print("Extracted aspect-dimension pairs:", extracted_pairs)
# e.g. [(food, taste), (service, speed)]

# ---------------------------
# STEP 2: Sentiment Classification with BERT
# ---------------------------

# Load pretrained BERT model for sentiment classification
tokenizer = BertTokenizer.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")
model = BertForSequenceClassification.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")

def classify_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    outputs = model(**inputs)
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    sentiment = torch.argmax(probs, dim=1).item()
    return ["Very Negative", "Negative", "Neutral", "Positive", "Very Positive"][sentiment]

# For each aspect–dimension pair, classify sentiment
pairs = [("food", "taste"), ("service", "speed")]
for aspect, dimension in pairs:
    subtext = f"{aspect} {dimension}: {review}"
    sentiment = classify_sentiment(subtext)
    print(f"{aspect} ({dimension}) → {sentiment}")
